{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33f82cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9869e387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Requirement             Type  \\\n",
      "0  'The system shall refresh the display every 60...      Performance   \n",
      "1  'If projected the data must be readable. On a ...        Usability   \n",
      "2  'The product shall be available during normal ...     Availability   \n",
      "3  'If projected the data must be understandable....        Usability   \n",
      "4  'The product shall ensure that it can only be ...         Security   \n",
      "5  'The product shall be intuitive and self-expla...        Usability   \n",
      "6  'The product shall respond fast to keep up-to-...      Performance   \n",
      "7  'The system shall link Events back to either t...  Maintainability   \n",
      "8  'The system shall link Events back to either t...      Portability   \n",
      "9  'The system shall be used by realtors with no ...        Usability   \n",
      "\n",
      "  Unnamed: 2 Unnamed: 3  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n",
      "4        NaN        NaN  \n",
      "5        NaN        NaN  \n",
      "6        NaN        NaN  \n",
      "7        NaN        NaN  \n",
      "8        NaN        NaN  \n",
      "9        NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 1. Load your dataset\n",
    "df = pd.read_csv(\"C:/Users/yomna/Downloads/requirements_combined_yomna.csv\")\n",
    "\n",
    "# 2. Split the Type column by comma and remove any extra spaces\n",
    "df[\"Type\"] = df[\"Type\"].apply(lambda x: re.split(r'[;,]', str(x)))\n",
    "\n",
    "# 3. Explode the rows so that each Type value gets its own row\n",
    "df = df.explode(\"Type\")\n",
    "\n",
    "# 4. Remove spaces again (in case of \" Scalability\" or \" Portability\")\n",
    "df[\"Type\"] = df[\"Type\"].str.strip()\n",
    "\n",
    "# 5. (Optional) Reset index for clarity\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# 6. Check the result\n",
    "print(df.head(10))\n",
    "\n",
    "# 7. Save the cleaned file if you want\n",
    "df.to_csv(\"C:/Users/yomna/Downloads/test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cdc5ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Requirement Type Unnamed: 2  \\\n",
      "0  'The system shall refresh the display every 60...   PE        NaN   \n",
      "1  'If projected the data must be readable. On a ...   US        NaN   \n",
      "2  'The product shall be available during normal ...    A        NaN   \n",
      "3  'If projected the data must be understandable....   US        NaN   \n",
      "4  'The product shall ensure that it can only be ...   SE        NaN   \n",
      "5  'The product shall be intuitive and self-expla...   US        NaN   \n",
      "6  'The product shall respond fast to keep up-to-...   PE        NaN   \n",
      "7  'The system shall link Events back to either t...   MN        NaN   \n",
      "8  'The system shall link Events back to either t...   PO        NaN   \n",
      "9  'The system shall be used by realtors with no ...   US        NaN   \n",
      "\n",
      "  Unnamed: 3  \n",
      "0        NaN  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n",
      "5        NaN  \n",
      "6        NaN  \n",
      "7        NaN  \n",
      "8        NaN  \n",
      "9        NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Read data\n",
    "df = pd.read_csv(\"C:/Users/yomna/Downloads/test.csv\")\n",
    "\n",
    "# 2. Mapping dictionary (lowercase keys)\n",
    "type_mapping = {\n",
    "    \"performance\": \"PE\",\n",
    "    \"scalability\": \"SC\",\n",
    "    \"maintainability\": \"MN\",\n",
    "    \"security\": \"SE\",\n",
    "    \"operability\": \"O\",\n",
    "    \"usability\": \"US\",\n",
    "    \"portability\": \"PO\",\n",
    "    \"availability\": \"A\"\n",
    "}\n",
    "\n",
    "# 3. Clean spaces and lowercase temporarily for mapping\n",
    "def map_type(value):\n",
    "    if pd.isna(value):  # ignore NaN\n",
    "        return value\n",
    "    value_clean = value.strip()\n",
    "    value_lower = value_clean.lower()\n",
    "    \n",
    "    # if it's already an abbreviation, leave it as is\n",
    "    if value_clean.upper() in type_mapping.values():\n",
    "        return value_clean.upper()\n",
    "    \n",
    "    # else, map it if found in dictionary\n",
    "    return type_mapping.get(value_lower, value_clean)\n",
    "\n",
    "df[\"Type\"] = df[\"Type\"].apply(map_type)\n",
    "\n",
    "# 4. Check result\n",
    "print(df.head(10))\n",
    "\n",
    "# 5. Save cleaned version\n",
    "df.to_csv(\"C:/Users/yomna/Downloads/cleaned_file.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8c1bb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset cleaned successfully!\n",
      "Number of rows after cleaning: 404\n",
      "                                         Requirement Type Unnamed: 2  \\\n",
      "0  'The system shall refresh the display every 60...   PE        NaN   \n",
      "1  'If projected the data must be readable. On a ...   US        NaN   \n",
      "2  'The product shall be available during normal ...    A        NaN   \n",
      "3  'If projected the data must be understandable....   US        NaN   \n",
      "4  'The product shall ensure that it can only be ...   SE        NaN   \n",
      "5  'The product shall be intuitive and self-expla...   US        NaN   \n",
      "6  'The product shall respond fast to keep up-to-...   PE        NaN   \n",
      "7  'The system shall link Events back to either t...   MN        NaN   \n",
      "8  'The system shall link Events back to either t...   PO        NaN   \n",
      "9  'The system shall be used by realtors with no ...   US        NaN   \n",
      "\n",
      "  Unnamed: 3  \n",
      "0        NaN  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n",
      "5        NaN  \n",
      "6        NaN  \n",
      "7        NaN  \n",
      "8        NaN  \n",
      "9        NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yomna\\AppData\\Local\\Temp\\ipykernel_14792\\1222360798.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Read the dataset\n",
    "df = pd.read_csv(\"C:/Users/yomna/Downloads/cleaned_file.csv\")\n",
    "\n",
    "# 2. Remove leading/trailing spaces from all string columns\n",
    "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# 3. Drop completely empty rows (if any)\n",
    "df = df.dropna(how='all')\n",
    "\n",
    "# 4. Drop duplicate rows (exact duplicates)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# 5. Drop rows where important columns are missing (like Requirement or Type)\n",
    "df = df.dropna(subset=[\"Requirement\", \"Type\"])\n",
    "\n",
    "# 6. Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# 7. Optional: Convert text columns to proper case or uppercase if you want\n",
    "df[\"Type\"] = df[\"Type\"].str.upper()\n",
    "\n",
    "# 8. Check summary after cleaning\n",
    "print(\"‚úÖ Dataset cleaned successfully!\")\n",
    "print(f\"Number of rows after cleaning: {len(df)}\")\n",
    "print(df.head(10))\n",
    "\n",
    "# 9. Save the cleaned dataset\n",
    "df.to_csv(\"C:/Users/yomna/Downloads/final_cleaned_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf53402",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1d28b2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               NFR   Level\n",
      "0      Performance    High\n",
      "1         Security    High\n",
      "2      Scalability    High\n",
      "3        Usability    High\n",
      "4  Maintainability  Medium\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1Ô∏è‚É£ ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑŸÄ dataset\n",
    "dataset = pd.read_csv(\"C:/Users/yomna/Downloads/architectures_dataset.csv\")\n",
    "\n",
    "# 2Ô∏è‚É£ ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖŸÅÿ™ÿßÿ≠Ÿäÿ© ŸÑŸÉŸÑ level\n",
    "keywords = {\n",
    "    \"High\": [\"must\", \"ensure\", \"high\", \"large\", \"guarantee\", \"secure\", \"fast\", \"scalable\", \"availability\", \"critical\"],\n",
    "    \"Medium\": [\"should\", \"moderate\", \"reasonable\", \"adequate\", \"normal\", \"balance\"],\n",
    "    \"Low\": [\"optional\", \"basic\", \"minimal\", \"simple\", \"less\", \"limited\"]\n",
    "}\n",
    "\n",
    "# 3Ô∏è‚É£ NFRs ÿßŸÑÿ¨ÿßŸäÿ© ŸÖŸÜ ÿßŸÑŸÄ SRS\n",
    "nfrs = [\n",
    "    {\n",
    "        \"title\": \"Performance\",\n",
    "        \"description\": \"The system must provide a fast and efficient parsing process, with a response time of less than 2 seconds for a typical CV.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Security\",\n",
    "        \"description\": \"The system must ensure the confidentiality, integrity, and availability of user data, and must comply with all relevant data protection regulations.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Scalability\",\n",
    "        \"description\": \"The system should be designed to scale horizontally, with the ability to handle a large number of concurrent users and a high volume of CVs.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Usability\",\n",
    "        \"description\": \"The system must be user-friendly and easy to navigate, with clear and concise instructions and feedback.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Maintainability\",\n",
    "        \"description\": \"The system should be designed to be easily maintainable, with clear and modular code and a robust testing framework.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 4Ô∏è‚É£ ÿØÿßŸÑÿ© ŸÑÿ™ÿ≠ÿØŸäÿØ ÿßŸÑŸÖÿ≥ÿ™ŸàŸâ ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖŸÅÿ™ÿßÿ≠Ÿäÿ©\n",
    "def detect_level(description):\n",
    "    desc = description.lower()\n",
    "    score = {\"High\": 0, \"Medium\": 0, \"Low\": 0}\n",
    "    for level, words in keywords.items():\n",
    "        for w in words:\n",
    "            if w in desc:\n",
    "                score[level] += 1\n",
    "    # ÿßÿÆÿ™Ÿäÿßÿ± ÿßŸÑŸÖÿ≥ÿ™ŸàŸâ ÿßŸÑÿ£ÿπŸÑŸâ\n",
    "    return max(score, key=score.get)\n",
    "\n",
    "# 5Ô∏è‚É£ ÿ™ÿ≠ÿØŸäÿØ ÿßŸÑŸÖÿ≥ÿ™ŸàŸâ ŸÑŸÉŸÑ NFR\n",
    "results = []\n",
    "for nfr in nfrs:\n",
    "    level = detect_level(nfr[\"description\"])\n",
    "    results.append({\"NFR\": nfr[\"title\"], \"Level\": level})\n",
    "\n",
    "# 6Ô∏è‚É£ ÿ™ÿ≠ŸàŸäŸÑ ÿßŸÑŸÜÿ™ÿßŸäÿ¨ ÿ•ŸÑŸâ DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2990345a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[87]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer, util\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# ---------- Step 1: Load data ----------\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mC:/Users/yomna/Downloads/ArchiMind1/GPARCHIMIND/non_functional_requirements.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# ---------- Step 1: Load data ----------\n",
    "with open(\"C:/Users/yomna/Downloads/ArchiMind1/GPARCHIMIND/non_functional_requirements.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    nfrs = json.load(f)\n",
    "\n",
    "architectures = pd.read_csv(\"architectures_dataset.csv\")\n",
    "\n",
    "# ---------- Step 2: Define reference meaning for each level ----------\n",
    "reference_levels = {\n",
    "    \"High\": \"The system must strongly satisfy this quality with maximum priority and strict constraints.\",\n",
    "    \"Medium\": \"The system should moderately satisfy this quality with reasonable performance and effort.\",\n",
    "    \"Low\": \"The system may satisfy this quality slightly or it is not a major concern for the system.\"\n",
    "}\n",
    "\n",
    "# ---------- Step 3: Initialize embedding model ----------\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# ---------- Step 4: Determine NFR level using semantic similarity ----------\n",
    "def get_level(description):\n",
    "    desc_emb = model.encode(description, convert_to_tensor=True)\n",
    "    sims = {}\n",
    "    for level, text in reference_levels.items():\n",
    "        sims[level] = util.cos_sim(desc_emb, model.encode(text, convert_to_tensor=True)).item()\n",
    "    return max(sims, key=sims.get)\n",
    "\n",
    "for nfr in nfrs:\n",
    "    desc = nfr.get(\"description\", \"\")\n",
    "    if not desc:\n",
    "        nfr[\"level\"] = \"Unknown\"\n",
    "    else:\n",
    "        nfr[\"level\"] = get_level(desc)\n",
    "\n",
    "# ---------- Step 5: Save NFRs with levels ----------\n",
    "with open(\"non_functional_requirements_with_levels.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(nfrs, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"‚úÖ Levels assigned and saved to non_functional_requirements_with_levels.json\")\n",
    "\n",
    "# ---------- Step 6: Map levels to numeric values ----------\n",
    "level_map = {\"Low\": 1, \"Medium\": 2, \"High\": 3}\n",
    "nfr_vector = {n[\"title\"].replace(\":\", \"\").strip(): level_map.get(n[\"level\"], 0) for n in nfrs}\n",
    "\n",
    "print(\"\\nüéØ Extracted NFR Levels:\")\n",
    "for k, v in nfr_vector.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# ---------- Step 7: Match with architectures dataset ----------\n",
    "def compute_diff(row):\n",
    "    diffs = []\n",
    "    for key, val in nfr_vector.items():\n",
    "        if key in row:\n",
    "            diffs.append(abs(row[key] - val))\n",
    "    return np.mean(diffs)\n",
    "\n",
    "architectures[\"avg_diff\"] = architectures.apply(compute_diff, axis=1)\n",
    "top_recommendations = architectures.sort_values(\"avg_diff\").head(5)\n",
    "\n",
    "top_recommendations.to_csv(\"top_architecture_recommendations.csv\", index=False)\n",
    "\n",
    "print(\"\\nüèóÔ∏è Top Recommended Architectures:\")\n",
    "print(top_recommendations[[\"Architecture Style\", \"avg_diff\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9d009b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yomna\\Downloads\\ArchiMind1\\GPARCHIMIND\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Extracted NFR Levels:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NFR</th>\n",
       "      <th>Level</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Performance</td>\n",
       "      <td>High</td>\n",
       "      <td>0.389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reliability</td>\n",
       "      <td>Variable</td>\n",
       "      <td>0.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Security</td>\n",
       "      <td>High</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Privacy</td>\n",
       "      <td>High</td>\n",
       "      <td>0.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scalability</td>\n",
       "      <td>High</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Usability</td>\n",
       "      <td>Variable</td>\n",
       "      <td>0.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Maintainability</td>\n",
       "      <td>Variable</td>\n",
       "      <td>0.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Compatibility</td>\n",
       "      <td>High</td>\n",
       "      <td>0.555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Integration</td>\n",
       "      <td>High</td>\n",
       "      <td>0.520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               NFR     Level  Confidence\n",
       "0      Performance      High       0.389\n",
       "1      Reliability  Variable       0.633\n",
       "2         Security      High       0.731\n",
       "3          Privacy      High       0.647\n",
       "4      Scalability      High       0.815\n",
       "5        Usability  Variable       0.637\n",
       "6  Maintainability  Variable       0.631\n",
       "7    Compatibility      High       0.555\n",
       "8      Integration      High       0.520"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèóÔ∏è Top Recommended Architectures:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Architecture Style</th>\n",
       "      <th>avg_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Event-Driven/ Messaging</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Serverless/FaaS</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Service Oriented (SOA)</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Microservices</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Event-Bus/Event Broker</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Architecture Style  avg_diff\n",
       "5   Event-Driven/ Messaging       0.4\n",
       "16          Serverless/FaaS       0.4\n",
       "4    Service Oriented (SOA)       0.6\n",
       "3             Microservices       0.6\n",
       "17   Event-Bus/Event Broker       0.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === AI-Based Architecture Recommender ===\n",
    "# By Yomna üí™üî•\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# ---------- 1Ô∏è‚É£ Load model ----------\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# ---------- 2Ô∏è‚É£ Load NFRs from JSON ----------\n",
    "with open(\"non_functional_requirements.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    nfr_data = json.load(f)\n",
    "\n",
    "# ---------- 3Ô∏è‚É£ Load architecture dataset ----------\n",
    "arch_df = pd.read_csv(\"architectures_dataset.csv\")\n",
    "\n",
    "# Clean columns and rename if needed\n",
    "arch_df.columns = arch_df.columns.str.strip()\n",
    "\n",
    "# ---------- 4Ô∏è‚É£ Define reference sentences for NFR levels ----------\n",
    "level_examples = {\n",
    "    \"Performance\": {\n",
    "        \"High\": \"The system must respond in real-time or under 1 second.\",\n",
    "        \"Variable\": \"The system should perform efficiently under normal loads.\",\n",
    "        \"Low\": \"Performance is not critical; background tasks can be delayed.\"\n",
    "    },\n",
    "    \"Security\": {\n",
    "        \"High\": \"The system must use encryption, access control, and secure authentication.\",\n",
    "        \"Variable\": \"The system should have moderate security controls.\",\n",
    "        \"Low\": \"Basic security is sufficient.\"\n",
    "    },\n",
    "    \"Scalability\": {\n",
    "        \"High\": \"The system must scale horizontally and handle thousands of concurrent users.\",\n",
    "        \"Variable\": \"The system should support moderate scaling.\",\n",
    "        \"Low\": \"Scalability is not a major concern.\"\n",
    "    },\n",
    "    \"Maintainability\": {\n",
    "        \"High\": \"System should be modular, easily extendable, and support CI/CD.\",\n",
    "        \"Variable\": \"System should be maintainable with moderate effort.\",\n",
    "        \"Low\": \"Maintenance complexity is acceptable.\"\n",
    "    },\n",
    "    \"Usability\": {\n",
    "        \"High\": \"Interface must be intuitive and easy for all users with minimal training.\",\n",
    "        \"Variable\": \"Interface should be user-friendly for most users.\",\n",
    "        \"Low\": \"Usability is not a major priority.\"\n",
    "    },\n",
    "    \"Reliability\": {\n",
    "        \"High\": \"The system must have fault-tolerance and minimal downtime.\",\n",
    "        \"Variable\": \"System should recover from occasional failures.\",\n",
    "        \"Low\": \"Occasional failures are acceptable.\"\n",
    "    },\n",
    "    \"Privacy\": {\n",
    "        \"High\": \"System must ensure full data privacy and comply with GDPR or local laws.\",\n",
    "        \"Variable\": \"Privacy controls should be implemented moderately.\",\n",
    "        \"Low\": \"Privacy is not a main concern.\"\n",
    "    },\n",
    "    \"Integration\": {\n",
    "        \"High\": \"System must integrate seamlessly with external systems in real-time.\",\n",
    "        \"Variable\": \"Integration should be supported through APIs.\",\n",
    "        \"Low\": \"Minimal integration needed.\"\n",
    "    },\n",
    "    \"Compatibility\": {\n",
    "        \"High\": \"System must run on multiple platforms and browsers without issues.\",\n",
    "        \"Variable\": \"System should support major platforms.\",\n",
    "        \"Low\": \"Compatibility is limited to few environments.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# ---------- 5Ô∏è‚É£ Determine NFR Levels ----------\n",
    "results = []\n",
    "for nfr in nfr_data:\n",
    "    title = nfr[\"title\"].replace(\":\", \"\").strip()\n",
    "    desc = nfr.get(\"description\", \"\")\n",
    "\n",
    "    if title not in level_examples:\n",
    "        continue  # skip unknown NFRs\n",
    "\n",
    "    desc_emb = model.encode(desc, convert_to_tensor=True)\n",
    "    sims = {}\n",
    "\n",
    "    for lvl, example_text in level_examples[title].items():\n",
    "        lvl_emb = model.encode(example_text, convert_to_tensor=True)\n",
    "        sims[lvl] = float(util.cos_sim(desc_emb, lvl_emb))\n",
    "\n",
    "    best_level = max(sims, key=sims.get)\n",
    "    results.append({\"NFR\": title, \"Level\": best_level, \"Confidence\": round(sims[best_level], 3)})\n",
    "\n",
    "nfr_levels_df = pd.DataFrame(results)\n",
    "print(\"‚úÖ Extracted NFR Levels:\")\n",
    "display(nfr_levels_df)\n",
    "\n",
    "# ---------- 6Ô∏è‚É£ Match to Architecture Dataset ----------\n",
    "# map NFR codes\n",
    "nfr_map = {\n",
    "    \"Performance\": \"PE\", \"Scalability\": \"SC\", \"Maintainability\": \"MN\",\n",
    "    \"Availability\": \"A\", \"Security\": \"SE\", \"Usability\": \"US\",\n",
    "    \"Portability\": \"PO\", \"Operability\": \"O\"\n",
    "}\n",
    "\n",
    "# Convert text levels to numeric scale for comparison\n",
    "level_to_num = {\"Low\": 1, \"Variable\": 2, \"High\": 3}\n",
    "\n",
    "arch_df_scores = arch_df.copy()\n",
    "arch_df_scores = arch_df_scores.set_index(\"Architecture Style\")\n",
    "\n",
    "# Compare similarity for each architecture\n",
    "diffs = []\n",
    "for arch, row in arch_df_scores.iterrows():\n",
    "    total_diff = 0\n",
    "    count = 0\n",
    "    for _, nfr in nfr_levels_df.iterrows():\n",
    "        nfr_name = nfr[\"NFR\"]\n",
    "        if nfr_name in nfr_map:\n",
    "            col = nfr_map[nfr_name]\n",
    "            if col in row:\n",
    "                total_diff += abs(row[col] - level_to_num[nfr[\"Level\"]])\n",
    "                count += 1\n",
    "    avg_diff = total_diff / count if count > 0 else None\n",
    "    diffs.append({\"Architecture Style\": arch, \"avg_diff\": avg_diff})\n",
    "\n",
    "# ---------- 7Ô∏è‚É£ Final Recommendation ----------\n",
    "arch_ranking = pd.DataFrame(diffs).sort_values(by=\"avg_diff\", ascending=True)\n",
    "print(\"\\nüèóÔ∏è Top Recommended Architectures:\")\n",
    "display(arch_ranking.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df2ad1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Predictions + Recommendations saved to architecture_recommendations.json\n",
      "\n",
      "üèóÔ∏è Best Matching Architectures:\n",
      "   ‚Ä¢ Hexagonal (ports& adapters)  (average difference = 0.25)\n",
      "   ‚Ä¢ Layered (N-Tier)  (average difference = 0.50)\n",
      "   ‚Ä¢ Client server  (average difference = 0.50)\n",
      "   ‚Ä¢ Monolithic  (average difference = 0.75)\n",
      "   ‚Ä¢ Event-Driven/ Messaging  (average difference = 0.75)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# ============================\n",
    "#  LOAD MODELS AND DATA\n",
    "# ============================\n",
    "\n",
    "# Load trained model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Load training data\n",
    "with open(\"nfr_training_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    training_data = json.load(f)\n",
    "\n",
    "# Load NFRs to predict\n",
    "with open(\"non_functional_requirements.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    nfr_list = json.load(f)\n",
    "\n",
    "# Load Architecture Dataset\n",
    "arch_df = pd.read_csv(\"C:/Users/yomna/Downloads/ArchitectureDataset.csv\")\n",
    "\n",
    "# ============================\n",
    "#  CONFIGS & MAPPINGS\n",
    "# ============================\n",
    "\n",
    "# Mapping for text levels\n",
    "level_map = {\"High\": 3, \"Variable\": 2, \"Low\": 1}\n",
    "\n",
    "# Mapping between CSV short types and full NFR names\n",
    "type_mapping = {\n",
    "    \"PE\": \"Performance\",\n",
    "    \"RE\": \"Reliability\",\n",
    "    \"SC\": \"Scalability\",\n",
    "    \"SE\": \"Security\",\n",
    "    \"US\": \"Usability\",\n",
    "    \"MA\": \"Maintainability\",\n",
    "    \"CO\": \"Compatibility\",\n",
    "    \"IN\": \"Integration\",\n",
    "    \"PR\": \"Privacy\"\n",
    "}\n",
    "\n",
    "# ============================\n",
    "#  PREDICTION FUNCTION\n",
    "# ============================\n",
    "\n",
    "def predict_level(nfr_type, new_text):\n",
    "    \"\"\"Predicts the level (High/Variable/Low) for a given NFR text.\"\"\"\n",
    "    if nfr_type not in training_data:\n",
    "        return \"‚ö†Ô∏è Unknown NFR type\"\n",
    "\n",
    "    examples = training_data[nfr_type]\n",
    "    if len(examples) == 0:\n",
    "        return \"‚ö†Ô∏è No training examples\"\n",
    "\n",
    "    example_texts = [ex[\"text\"] for ex in examples]\n",
    "    example_labels = [ex[\"label\"] for ex in examples]\n",
    "\n",
    "    # Create embeddings\n",
    "    new_emb = model.encode(new_text, convert_to_tensor=True)\n",
    "    example_embs = model.encode(example_texts, convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    sims = util.pytorch_cos_sim(new_emb, example_embs)[0]\n",
    "    best_idx = int(torch.argmax(sims))\n",
    "    return example_labels[best_idx]\n",
    "\n",
    "# ============================\n",
    "#  STEP 1: Predict NFR Levels\n",
    "# ============================\n",
    "\n",
    "results = []\n",
    "predicted_levels = {}\n",
    "\n",
    "for item in nfr_list:\n",
    "    title = item[\"title\"].replace(\":\", \"\").strip()\n",
    "    desc = item[\"description\"]\n",
    "    \n",
    "    if title in training_data:\n",
    "        predicted = predict_level(title, desc)\n",
    "        results.append({\n",
    "            \"title\": title,\n",
    "            \"description\": desc,\n",
    "            \"predicted_level\": predicted\n",
    "        })\n",
    "        if predicted in level_map:\n",
    "            predicted_levels[title] = level_map[predicted]\n",
    "    else:\n",
    "        results.append({\n",
    "            \"title\": title,\n",
    "            \"description\": desc,\n",
    "            \"predicted_level\": \"‚ö†Ô∏è Not in trained categories\"\n",
    "        })\n",
    "\n",
    "# ============================\n",
    "#  STEP 2: Match Architectures\n",
    "# ============================\n",
    "\n",
    "architecture_scores = {}\n",
    "\n",
    "for arch in arch_df[\"Architecture\"].unique():\n",
    "    arch_rows = arch_df[arch_df[\"Architecture\"] == arch]\n",
    "    total_diff = 0\n",
    "    count = 0\n",
    "\n",
    "    for _, row in arch_rows.iterrows():\n",
    "        short_type = row[\"Type\"]\n",
    "\n",
    "        # Safely convert Level to int\n",
    "        try:\n",
    "            level = int(row[\"Level\"])\n",
    "        except (ValueError, TypeError):\n",
    "            continue\n",
    "\n",
    "        if short_type in type_mapping:\n",
    "            full_type = type_mapping[short_type]\n",
    "            if full_type in predicted_levels:\n",
    "                diff = abs(predicted_levels[full_type] - level)\n",
    "                total_diff += diff\n",
    "                count += 1\n",
    "\n",
    "    if count > 0:\n",
    "        avg_diff = total_diff / count\n",
    "        architecture_scores[arch] = avg_diff\n",
    "\n",
    "# Sort by lowest difference (best match)\n",
    "best_architectures = sorted(architecture_scores.items(), key=lambda x: x[1])\n",
    "\n",
    "# ============================\n",
    "#  STEP 3: Save & Print Output\n",
    "# ============================\n",
    "\n",
    "output = {\n",
    "    \"nfr_predictions\": results,\n",
    "    \"best_architecture_matches\": best_architectures[:5]  # top 5\n",
    "}\n",
    "\n",
    "with open(\"architecture_recommendations.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Print top matches\n",
    "print(\"\\n‚úÖ Predictions + Recommendations saved to architecture_recommendations.json\\n\")\n",
    "if best_architectures:\n",
    "    print(\"üèóÔ∏è Best Matching Architectures:\")\n",
    "    for arch, score in best_architectures[:5]:\n",
    "        print(f\"   ‚Ä¢ {arch}  (average difference = {score:.2f})\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No architecture matches found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
