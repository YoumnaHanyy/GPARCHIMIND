{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33f82cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9869e387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Requirement             Type  \\\n",
      "0  'The system shall refresh the display every 60...      Performance   \n",
      "1  'If projected the data must be readable. On a ...        Usability   \n",
      "2  'The product shall be available during normal ...     Availability   \n",
      "3  'If projected the data must be understandable....        Usability   \n",
      "4  'The product shall ensure that it can only be ...         Security   \n",
      "5  'The product shall be intuitive and self-expla...        Usability   \n",
      "6  'The product shall respond fast to keep up-to-...      Performance   \n",
      "7  'The system shall link Events back to either t...  Maintainability   \n",
      "8  'The system shall link Events back to either t...      Portability   \n",
      "9  'The system shall be used by realtors with no ...        Usability   \n",
      "\n",
      "  Unnamed: 2 Unnamed: 3  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n",
      "4        NaN        NaN  \n",
      "5        NaN        NaN  \n",
      "6        NaN        NaN  \n",
      "7        NaN        NaN  \n",
      "8        NaN        NaN  \n",
      "9        NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 1. Load your dataset\n",
    "df = pd.read_csv(\"C:/Users/yomna/Downloads/requirements_combined_yomna.csv\")\n",
    "\n",
    "# 2. Split the Type column by comma and remove any extra spaces\n",
    "df[\"Type\"] = df[\"Type\"].apply(lambda x: re.split(r'[;,]', str(x)))\n",
    "\n",
    "# 3. Explode the rows so that each Type value gets its own row\n",
    "df = df.explode(\"Type\")\n",
    "\n",
    "# 4. Remove spaces again (in case of \" Scalability\" or \" Portability\")\n",
    "df[\"Type\"] = df[\"Type\"].str.strip()\n",
    "\n",
    "# 5. (Optional) Reset index for clarity\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# 6. Check the result\n",
    "print(df.head(10))\n",
    "\n",
    "# 7. Save the cleaned file if you want\n",
    "df.to_csv(\"C:/Users/yomna/Downloads/test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cdc5ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Requirement Type Unnamed: 2  \\\n",
      "0  'The system shall refresh the display every 60...   PE        NaN   \n",
      "1  'If projected the data must be readable. On a ...   US        NaN   \n",
      "2  'The product shall be available during normal ...    A        NaN   \n",
      "3  'If projected the data must be understandable....   US        NaN   \n",
      "4  'The product shall ensure that it can only be ...   SE        NaN   \n",
      "5  'The product shall be intuitive and self-expla...   US        NaN   \n",
      "6  'The product shall respond fast to keep up-to-...   PE        NaN   \n",
      "7  'The system shall link Events back to either t...   MN        NaN   \n",
      "8  'The system shall link Events back to either t...   PO        NaN   \n",
      "9  'The system shall be used by realtors with no ...   US        NaN   \n",
      "\n",
      "  Unnamed: 3  \n",
      "0        NaN  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n",
      "5        NaN  \n",
      "6        NaN  \n",
      "7        NaN  \n",
      "8        NaN  \n",
      "9        NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Read data\n",
    "df = pd.read_csv(\"C:/Users/yomna/Downloads/test.csv\")\n",
    "\n",
    "# 2. Mapping dictionary (lowercase keys)\n",
    "type_mapping = {\n",
    "    \"performance\": \"PE\",\n",
    "    \"scalability\": \"SC\",\n",
    "    \"maintainability\": \"MN\",\n",
    "    \"security\": \"SE\",\n",
    "    \"operability\": \"O\",\n",
    "    \"usability\": \"US\",\n",
    "    \"portability\": \"PO\",\n",
    "    \"availability\": \"A\"\n",
    "}\n",
    "\n",
    "# 3. Clean spaces and lowercase temporarily for mapping\n",
    "def map_type(value):\n",
    "    if pd.isna(value):  # ignore NaN\n",
    "        return value\n",
    "    value_clean = value.strip()\n",
    "    value_lower = value_clean.lower()\n",
    "    \n",
    "    # if it's already an abbreviation, leave it as is\n",
    "    if value_clean.upper() in type_mapping.values():\n",
    "        return value_clean.upper()\n",
    "    \n",
    "    # else, map it if found in dictionary\n",
    "    return type_mapping.get(value_lower, value_clean)\n",
    "\n",
    "df[\"Type\"] = df[\"Type\"].apply(map_type)\n",
    "\n",
    "# 4. Check result\n",
    "print(df.head(10))\n",
    "\n",
    "# 5. Save cleaned version\n",
    "df.to_csv(\"C:/Users/yomna/Downloads/cleaned_file.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8c1bb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset cleaned successfully!\n",
      "Number of rows after cleaning: 404\n",
      "                                         Requirement Type Unnamed: 2  \\\n",
      "0  'The system shall refresh the display every 60...   PE        NaN   \n",
      "1  'If projected the data must be readable. On a ...   US        NaN   \n",
      "2  'The product shall be available during normal ...    A        NaN   \n",
      "3  'If projected the data must be understandable....   US        NaN   \n",
      "4  'The product shall ensure that it can only be ...   SE        NaN   \n",
      "5  'The product shall be intuitive and self-expla...   US        NaN   \n",
      "6  'The product shall respond fast to keep up-to-...   PE        NaN   \n",
      "7  'The system shall link Events back to either t...   MN        NaN   \n",
      "8  'The system shall link Events back to either t...   PO        NaN   \n",
      "9  'The system shall be used by realtors with no ...   US        NaN   \n",
      "\n",
      "  Unnamed: 3  \n",
      "0        NaN  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n",
      "5        NaN  \n",
      "6        NaN  \n",
      "7        NaN  \n",
      "8        NaN  \n",
      "9        NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yomna\\AppData\\Local\\Temp\\ipykernel_14792\\1222360798.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Read the dataset\n",
    "df = pd.read_csv(\"C:/Users/yomna/Downloads/cleaned_file.csv\")\n",
    "\n",
    "# 2. Remove leading/trailing spaces from all string columns\n",
    "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# 3. Drop completely empty rows (if any)\n",
    "df = df.dropna(how='all')\n",
    "\n",
    "# 4. Drop duplicate rows (exact duplicates)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# 5. Drop rows where important columns are missing (like Requirement or Type)\n",
    "df = df.dropna(subset=[\"Requirement\", \"Type\"])\n",
    "\n",
    "# 6. Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# 7. Optional: Convert text columns to proper case or uppercase if you want\n",
    "df[\"Type\"] = df[\"Type\"].str.upper()\n",
    "\n",
    "# 8. Check summary after cleaning\n",
    "print(\"‚úÖ Dataset cleaned successfully!\")\n",
    "print(f\"Number of rows after cleaning: {len(df)}\")\n",
    "print(df.head(10))\n",
    "\n",
    "# 9. Save the cleaned dataset\n",
    "df.to_csv(\"C:/Users/yomna/Downloads/final_cleaned_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80c4387c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Levels Assigned & File Saved Successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the filtered nfr dataset\n",
    "df = pd.read_csv(\"C:/Users/yomna/Downloads/final_cleaned_dataset.csv\")\n",
    "\n",
    "# Convert requirement text to lowercase to avoid case issues\n",
    "df['Requirement'] = df['Requirement'].str.lower()\n",
    "\n",
    "def get_level(req):\n",
    "    if any(k in req for k in ['shall', 'must', 'required', 'mandate']):\n",
    "        return 3  # High\n",
    "    elif any(k in req for k in ['should', 'recommended']):\n",
    "        return 2  # Medium\n",
    "    elif any(k in req for k in ['may', 'optional', 'could']):\n",
    "        return 1  # Low\n",
    "    else:\n",
    "        return 2  # default: medium\n",
    "\n",
    "df['Level'] = df['Requirement'].apply(get_level)\n",
    "\n",
    "# Save updated dataset\n",
    "df.to_csv(\"C:/Users/Yomna/Downloads/LevelDataset.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Levels Assigned & File Saved Successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a009c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "‚úÖ Best Parameters: {'C': 1, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "‚úÖ Accuracy: 48.15%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           A       0.56      0.71      0.62         7\n",
      "          MN       0.50      0.29      0.36         7\n",
      "           O       0.50      0.42      0.45        12\n",
      "          PE       0.45      0.38      0.42        13\n",
      "          PO       0.14      0.25      0.18         4\n",
      "          SC       0.40      0.33      0.36         6\n",
      "          SE       0.62      0.53      0.57        15\n",
      "          US       0.50      0.65      0.56        17\n",
      "\n",
      "    accuracy                           0.48        81\n",
      "   macro avg       0.46      0.45      0.44        81\n",
      "weighted avg       0.49      0.48      0.48        81\n",
      "\n",
      "\n",
      "Predicted Type: SC\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# üîπ Improved SVM Model for Requirement Type Classification\n",
    "# ==========================================\n",
    "\n",
    "# 1. Import libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 2. Load dataset\n",
    "df = pd.read_csv(\"C:/Users/yomna/Downloads/final_cleaned_dataset.csv\")\n",
    "\n",
    "# 3. Clean the text\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()  # lowercase\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)  # remove symbols & numbers\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # remove extra spaces\n",
    "    return text\n",
    "\n",
    "df[\"Requirement\"] = df[\"Requirement\"].apply(clean_text)\n",
    "\n",
    "# 4. Split the data\n",
    "X = df[\"Requirement\"]\n",
    "y = df[\"Type\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 5. TF-IDF Vectorization (1‚Äì3 grams)\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1, 3),\n",
    "    max_df=0.9,\n",
    "    min_df=1\n",
    ")\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# 6. Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    \"C\": [0.1, 1, 5, 10],\n",
    "    \"loss\": [\"squared_hinge\"],\n",
    "    \"penalty\": [\"l2\"]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    LinearSVC(class_weight=\"balanced\"),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train_tfidf, y_train)\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# 7. Evaluate\n",
    "y_pred = best_model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "\n",
    "print(\"\\n‚úÖ Best Parameters:\", grid.best_params_)\n",
    "print(f\"‚úÖ Accuracy: {accuracy:.2f}%\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# 8. Test with a new requirement\n",
    "new_req = [\"The system is designed to efficiently handle a growing number of users\"]\n",
    "new_vec = vectorizer.transform(new_req)\n",
    "pred = best_model.predict(new_vec)\n",
    "print(\"\\nPredicted Type:\", pred[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4cdc9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Predicted NFRs:\n",
      "                                         Requirement Type  Level\n",
      "0  the disputes system will facilitate direct dat...   SC      2\n",
      "1  the system shall be expected to manage the nur...   SC      3\n",
      "2  the system shall link events back to either th...   PO      3\n",
      "3  the product shall be available during normal b...    A      3\n",
      "4  all credit card information will be secured on...   SE      2\n",
      "5  the product should be able to be used by 90% o...    O      2\n",
      "6  the system shall link events back to either th...   PO      3\n",
      "7  a database management system such as oracle db...    O      2\n",
      "\n",
      "üèóÔ∏è Most Suitable Architecture: Monolithic\n",
      "‚úÖ Match Score: 0 / 8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# ========================================\n",
    "# STEP 1 ‚Äî Train the SVM Model (Type)\n",
    "# ========================================\n",
    "df = pd.read_csv(\"C:/Users/yomna/Downloads/final_cleaned_dataset.csv\")\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "df[\"Requirement\"] = df[\"Requirement\"].apply(clean_text)\n",
    "X = df[\"Requirement\"]\n",
    "y = df[\"Type\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,3), max_df=0.9, min_df=1)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "param_grid = {\"C\": [0.1, 1, 5], \"loss\": [\"squared_hinge\"], \"penalty\": [\"l2\"]}\n",
    "grid = GridSearchCV(LinearSVC(class_weight=\"balanced\"), param_grid, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train_tfidf, y_train)\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# ========================================\n",
    "# STEP 2 ‚Äî Define Level Function\n",
    "# ========================================\n",
    "def get_level(req):\n",
    "    req = req.lower()\n",
    "    if any(k in req for k in ['shall', 'must', 'required', 'mandate']):\n",
    "        return 3\n",
    "    elif any(k in req for k in ['should', 'recommended']):\n",
    "        return 2\n",
    "    elif any(k in req for k in ['may', 'optional', 'could']):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "# ========================================\n",
    "# STEP 3 ‚Äî Input New Requirements\n",
    "# ========================================\n",
    "new_reqs = [\n",
    "    \"the disputes system will facilitate direct data entry of a dispute case via a user interface that supports real time responses to the users.\",\n",
    "    \"the system shall be expected to manage the nursing program curriculum and class/clinical scheduling for a minimum of 5 years.\",\n",
    "    \"the system shall link events back to either the sync matrix 1.0 or the exercise managment tool 1.0 applications for modifications.\",\n",
    "    \"the product shall be available during normal business hours. as long as the user has\",\n",
    "    \"all credit card information will be secured on the server and only accessible by authorized\",\n",
    "    \"the product should be able to be used by 90% of novice users on the internet.\",\n",
    "    \"the system shall link events back to either the sync matrix 1.0 or the exercise managment tool 1.0 applications for modifications.\",\n",
    "    \"a database management system such as oracle db2 mysql or hsql will need to be integrated with the product.\"\n",
    "]\n",
    "\n",
    "# Predict type & level\n",
    "input_data = []\n",
    "for req in new_reqs:\n",
    "    vec = vectorizer.transform([clean_text(req)])\n",
    "    req_type = best_model.predict(vec)[0]\n",
    "    req_level = get_level(req)\n",
    "    input_data.append({\"Requirement\": req, \"Type\": req_type, \"Level\": req_level})\n",
    "\n",
    "input_df = pd.DataFrame(input_data)\n",
    "print(\"\\nüîπ Predicted NFRs:\")\n",
    "print(input_df)\n",
    "\n",
    "# ========================================\n",
    "# STEP 4 ‚Äî Match Against Architecture Dataset\n",
    "# ========================================\n",
    "arch_df = pd.read_csv(\"C:/Users/yomna/Downloads/ArchitectureDataset.csv\")\n",
    "\n",
    "# Compute match scores\n",
    "arch_scores = {}\n",
    "for arch in arch_df[\"Architecture\"].unique():\n",
    "    arch_subset = arch_df[arch_df[\"Architecture\"] == arch]\n",
    "    matches = 0\n",
    "    for _, row in input_df.iterrows():\n",
    "        same = arch_subset[(arch_subset[\"Type\"] == row[\"Type\"]) & (arch_subset[\"Level\"] == row[\"Level\"])]\n",
    "        if not same.empty:\n",
    "            matches += 1\n",
    "    arch_scores[arch] = matches\n",
    "\n",
    "best_arch = max(arch_scores, key=arch_scores.get)\n",
    "print(\"\\nüèóÔ∏è Most Suitable Architecture:\", best_arch)\n",
    "print(\"‚úÖ Match Score:\", arch_scores[best_arch], \"/\", len(input_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21a8e3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≤ Randomly generated NFR levels:\n",
      "PE: 3\n",
      "SC: 3\n",
      "MN: 2\n",
      "A: 2\n",
      "SE: 2\n",
      "US: 2\n",
      "PO: 1\n",
      "O: 3\n",
      "\n",
      "‚úÖ The most suitable Architecture Style for these random NFRs is: Monolithic\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Load architectures dataset\n",
    "df_arch = pd.read_csv(\"C:/Users/yomna/Downloads/architectures_dataset.csv\")\n",
    "\n",
    "# Define NFRs\n",
    "nfrs = [\"PE\", \"SC\", \"MN\", \"A\", \"SE\", \"US\", \"PO\", \"O\"]\n",
    "\n",
    "# Generate random NFR levels (1, 2, or 3)\n",
    "random_nfr_levels = {nfr: random.randint(1, 3) for nfr in nfrs}\n",
    "\n",
    "print(\"üé≤ Randomly generated NFR levels:\")\n",
    "for nfr, level in random_nfr_levels.items():\n",
    "    print(f\"{nfr}: {level}\")\n",
    "\n",
    "# Compare with each architecture style\n",
    "best_arch = None\n",
    "min_total_diff = float('inf')\n",
    "\n",
    "for _, row in df_arch.iterrows():\n",
    "    total_diff = sum(abs(row[nfr] - random_nfr_levels[nfr]) for nfr in nfrs)\n",
    "    if total_diff < min_total_diff:\n",
    "        min_total_diff = total_diff\n",
    "        best_arch = row[\"Architecture Style\"]\n",
    "\n",
    "print(f\"\\n‚úÖ The most suitable Architecture Style for these random NFRs is: {best_arch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f55de5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted NFRs from JSON: ['Performance:', 'Reliability:', 'Security:', 'Privacy:', 'Scalability:', 'Usability:', 'Maintainability:', 'Compatibility:', 'Integration:']\n",
      "Mapped abbreviations: ['PE', 'RE', 'SE', 'PR', 'SC', 'US', 'MA', 'CO', 'IN']\n",
      "üé≤ Random levels assigned to NFRs:\n",
      "PE: 2\n",
      "RE: 2\n",
      "SE: 1\n",
      "PR: 1\n",
      "SC: 1\n",
      "US: 3\n",
      "MA: 1\n",
      "CO: 1\n",
      "IN: 2\n",
      "\n",
      "‚úÖ Most suitable Architecture Style for these random NFRs: MVC (model-view-controller)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# 1Ô∏è‚É£ Load the JSON file\n",
    "with open(\"C:/Users/yomna/Downloads/ArchiMind1/GPARCHIMIND/non_functional_requirements.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    nfr_data = json.load(f)\n",
    "\n",
    "# 2Ô∏è‚É£ Extract titles (NFR types)\n",
    "nfr_titles = [item[\"title\"] for item in nfr_data]\n",
    "print(\"Extracted NFRs from JSON:\", nfr_titles)\n",
    "\n",
    "# 3Ô∏è‚É£ Optional: map them to abbreviations matching your architecture dataset\n",
    "# Example mapping:\n",
    "abbr_mapping = {\n",
    "    \"Performance\": \"PE\",\n",
    "    \"Scalability\": \"SC\",\n",
    "    \"Maintainability\": \"MN\",\n",
    "    \"Availability\": \"A\",\n",
    "    \"Security\": \"SE\",\n",
    "    \"Usability\": \"US\",\n",
    "    \"Portability\": \"PO\",\n",
    "    \"Operability\": \"O\",\n",
    "    \"Accuracy\": \"AC\",\n",
    "    \"Response time\": \"RT\"\n",
    "}\n",
    "\n",
    "nfr_abbrs = [abbr_mapping.get(title, title[:2].upper()) for title in nfr_titles]\n",
    "print(\"Mapped abbreviations:\", nfr_abbrs)\n",
    "\n",
    "# 4Ô∏è‚É£ Generate random levels for each NFR\n",
    "random_levels = {abbr: random.randint(1,3) for abbr in nfr_abbrs}\n",
    "print(\"üé≤ Random levels assigned to NFRs:\")\n",
    "for nfr, level in random_levels.items():\n",
    "    print(f\"{nfr}: {level}\")\n",
    "\n",
    "# 5Ô∏è‚É£ Compare with architectures_dataset.csv\n",
    "df_arch = pd.read_csv(\"C:/Users/yomna/Downloads/architectures_dataset.csv\")\n",
    "\n",
    "best_arch = None\n",
    "min_total_diff = float('inf')\n",
    "\n",
    "for _, row in df_arch.iterrows():\n",
    "    total_diff = 0\n",
    "    for nfr in nfr_abbrs:\n",
    "        if nfr in row:  # in case the architecture dataset doesn't have this NFR\n",
    "            total_diff += abs(row[nfr] - random_levels[nfr])\n",
    "    if total_diff < min_total_diff:\n",
    "        min_total_diff = total_diff\n",
    "        best_arch = row[\"Architecture Style\"]\n",
    "\n",
    "print(f\"\\n‚úÖ Most suitable Architecture Style for these random NFRs: {best_arch}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf53402",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
